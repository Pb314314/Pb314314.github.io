---
layout: about
title: about
permalink: /
subtitle: Master Student at <a href='https://www.gatech.edu/'>Georgia Tech</a>. Research in Efficient LLM Training & Reinforcement Learning.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p><strong>Email:</strong> bopang314@gmail.com</p>
    <p><strong>GitHub:</strong> <a href="https://github.com/Pb314314">Pb314314</a></p>
    <p><strong>LinkedIn:</strong> <a href="https://www.linkedin.com/in/bo-pang-344225292/">Bo Pang</a></p>
    <p><a href="/assets/pdf/cv.pdf" target="_blank">Download CV</a></p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am a Master's student at Georgia Tech, passionate about making large language models more efficient and scalable. My research focuses on:

- **Efficient Long-Context Training**: Developing novel attention mechanisms to reduce computational overhead in long-context language model training
- **Reinforcement Learning for LLMs**: Exploring fast synchronous reinforcement learning methods for large language models
- **Systems for ML**: Building scalable systems to support efficient machine learning workloads

I have contributed to several research projects, including work on core attention disaggregation (MLSys 2026) and online context learning for LLM reinforcement learning (OSDI 2026). I also participated in technical reports for Kimi Linear and Kimi K2.5.

In this blog, I share my thoughts and insights on machine learning, systems research, and the latest developments in the field. Feel free to reach out if you'd like to collaborate or discuss research ideas!
